---
layout: post
title: 随想：关于正则化解决过拟合问题
author: 牛教授
color: 00897B
description: 神经网络的学习方式在某些程度上与人类学习方式相似。
---

过拟合有两个解决办法，其一为增加训练数据，其二为正则化。我是这样理解的：  
神经网络的学习方式在某些程度上与人类学习方式相似。  
比如，需要经验的行业--医学。专家诊断疾病的过程首先要搜集信息：性别、性别、疾病史、症状发生的规律等等。然后根据这些信息在脑海中已知的疾病中进行筛选比对。诊断的过程类似于神经网络的推理过程，大脑里的知识库就是训练好参数的神经网络。而医学的知识库是如何得到的呢？这当然离不开统计。比如人类只见过一两个乳腺癌的病人，很难总结出这疾病有什么特点，甚至会形成“偏见”，诸如：个子矮的女人得乳腺癌、乳腺癌只有女性才有。需要经历几十个病例（甚至更多）之后才能总结出来规律，医学教材上的知识大都这样得来。  
更多的病例，也就是增加训练数据；正则化就是惩罚过于具体的特征。  

由此，我想到：  

- “通用型”神经网络应该从简单的事情开始，就像教小孩子一样，先学习什么是直线、角、多边形、曲线，学习光、影，再逐步递进，而不是 CNN 那样直接构建出许多层。这之间的区别是，后者只能根据特定的任务优化超参数，做出适合那个任务的模型，比如识别车牌，但是这样的网络很难少量改动用于识别猫；而前者可能更具有灵活性，学习到的基础知识应该可以很容易放到更复杂的问题中，猫眼睛的圆和太阳的圆本来就是同一种形状。相当于让神经网络分成不同级别的“层”和“模块”，解偶联。  
- 当训练量少的情况，就不应将问题过度具体，比如现有的资源就不应该直接学习翻译的问题，因为人类的语言太过于复杂，而直接让神经网络做具体的翻译工作似乎有点太急于求成。当前应用神经网络的翻译产品确实也有很多不太灵光的笑话。我觉得这结果在某种程度上算是过拟合，神经网络记住了某些场景的含义，而语言的大师能够说出你从未听过却一下子就能理解的话语。我一直认为神经网络的学习之路逃不出人脑的学习方法，踏实地从基础到高级才能扎实进步，否则可能到了某种程度就遭遇瓶颈无法再进步了。  
